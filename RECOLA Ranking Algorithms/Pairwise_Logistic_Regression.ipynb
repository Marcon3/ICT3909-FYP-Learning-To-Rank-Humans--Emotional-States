{"cells":[{"cell_type":"markdown","metadata":{"id":"PUEfi_qNCvsy"},"source":["# Pairwise Transformation"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6732,"status":"ok","timestamp":1711039792140,"user":{"displayName":"Marcon Spiteri","userId":"03188949906581882183"},"user_tz":-60},"id":"XQb5FPyuKaQV"},"outputs":[],"source":["import os\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from joblib import dump, load\n","from sklearn.metrics import accuracy_score\n","from scipy.stats import pearsonr, kendalltau\n","from sklearn.model_selection import GroupKFold\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import RandomForestClassifier\n","from statsmodels.miscmodels.ordinal_model import OrderedModel\n","from statsmodels.tools.sm_exceptions import HessianInversionWarning\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["project_directory = r'C:\\Users\\marco\\OneDrive\\Desktop\\Final Year Project'\n","os.chdir(project_directory)\n","base_dir = os.getcwd() "]},{"cell_type":"markdown","metadata":{},"source":["- Evaluation Arousal"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3222551,"status":"ok","timestamp":1711043014689,"user":{"displayName":"Marcon Spiteri","userId":"03188949906581882183"},"user_tz":-60},"id":"CdU5zO2vb8Fg","outputId":"589c972a-1d87-41c2-bce4-f5135eac42cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processing data for median_arousal...\n","Dataset loaded.\n","Starting cross-validation for arousal...\n","\n","=====================================\n","Fold 1/10\n","Files for fold 0 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 2/10\n","Files for fold 1 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 3/10\n","Files for fold 2 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 4/10\n","Files for fold 3 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 5/10\n","Files for fold 4 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 6/10\n","Files for fold 5 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 7/10\n","Files for fold 6 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 8/10\n","Files for fold 7 already exist. Loading from disk.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 9/10\n","Pairwise transformation for fold 8 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 10/10\n","Pairwise transformation for fold 9 completed and data saved.\n","Starting Random Forest training...\n","Evaluation results saved.\n"]}],"source":["base_dir = 'RECOLA Ranking Algorithms'\n","arousal_dir = os.path.join(base_dir, 'Random Forest/Arousal')\n","evaluation_results_dir = os.path.join(base_dir, 'Evaluation/RandomForest')\n","\n","\n","def pairwise_transformation(X, Y, participant_ids, fold_number):\n","    transformed_data_path = os.path.join(arousal_dir, f'transformed_data_fold_{fold_number}.pkl')\n","    labels_path = os.path.join(arousal_dir, f'labels_fold_{fold_number}.pkl')\n","\n","    # Check if files already exist\n","    if os.path.exists(transformed_data_path) and os.path.exists(labels_path):\n","        print(f\"Files for fold {fold_number} already exist. Loading from disk.\")\n","        transformed_data = load(transformed_data_path)\n","        labels = load(labels_path)\n","    else:\n","        transformed_data = []\n","        labels = []\n","        unique_participants = np.unique(participant_ids)\n","\n","        for participant in unique_participants:\n","            participant_mask = participant_ids == participant\n","            X_participant = X[participant_mask]\n","            Y_participant = Y[participant_mask]\n","\n","            for i in range(len(X_participant)):\n","                for j in range(len(X_participant)):\n","                    if j == i:\n","                        continue\n","                    xi, xj = X_participant[i], X_participant[j]\n","                    yi, yj = Y_participant[i], Y_participant[j]\n","                    if yi > yj:\n","                        transformed_data.append(xi - xj)\n","                        labels.append(1)\n","                    elif yi < yj:\n","                        transformed_data.append(xj - xi)\n","                        labels.append(0)\n","\n","        # Save the transformed data and labels to disk\n","        dump(transformed_data, transformed_data_path)\n","        dump(labels, labels_path)\n","        print(f\"Pairwise transformation for fold {fold_number} completed and data saved.\")\n","\n","    return transformed_data_path, labels_path\n","\n","def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    ccc = numerator / denominator\n","    return ccc\n","\n","def pearson_correlation_coefficient(y_true, y_pred):\n","    pcc, _ = pearsonr(y_true, y_pred)\n","    return pcc\n","\n","def kendalls_tau_coefficient(y_true, y_pred):\n","\n","    tau, _ = kendalltau(y_true, y_pred)\n","    return tau\n","\n","def evaluate_individual_performance(clf, X_test, Y_test, group_labels):\n","    evaluation_results = []\n","\n","    for participant_id in np.unique(group_labels):\n","\n","        idx = group_labels == participant_id\n","        participant_features = X_test[idx]\n","        participant_labels = Y_test[idx]\n","\n","        # Compute mean feature values for participant\n","        mean_features = np.mean(participant_features, axis=0)\n","\n","        # Pairwise transformation\n","        transformed_features = participant_features - mean_features\n","\n","        # Pass the transformed data through the trained RF model to predict probabilities\n","        predicted_probabilities = clf.predict_proba(transformed_features)[:, 1]\n","\n","        # Calculate measures with the raw arousal values\n","        pcc_value = pearsonr(participant_labels, predicted_probabilities)[0]\n","        ccc_value = concordance_correlation_coefficient(participant_labels, predicted_probabilities)\n","        kendall_tau_value = kendalltau(participant_labels, predicted_probabilities)[0]\n","\n","        evaluation_results.append({\n","            'Participant ID': participant_id,\n","            'PCC': pcc_value,\n","            'CCC': ccc_value,\n","            'KendallTau': kendall_tau_value\n","        })\n","\n","    return pd.DataFrame(evaluation_results)\n","\n","evaluation_results = []\n","\n","def process_data_median_arousal(file_path):\n","    target_column = 'median_arousal'\n","    print(f\"\\nProcessing data for {target_column}...\")\n","\n","    combined_df = pd.read_csv(file_path)\n","    print(\"Dataset loaded.\")\n","\n","    excluded_features = [\n","        'VIDEO_40_LLD_AU1', 'VIDEO_40_LLD_AU2', 'VIDEO_40_LLD_AU4', 'VIDEO_40_LLD_AU5', 'VIDEO_40_LLD_AU6', 'VIDEO_40_LLD_AU7', 'VIDEO_40_LLD_AU9', 'VIDEO_40_LLD_AU11', 'VIDEO_40_LLD_AU12', 'VIDEO_40_LLD_AU15',\n","        'VIDEO_40_LLD_AU17', 'VIDEO_40_LLD_AU20', 'VIDEO_40_LLD_AU23', 'VIDEO_40_LLD_AU24', 'VIDEO_40_LLD_AU25', 'VIDEO_40_LLD_Yaw', 'VIDEO_40_LLD_Pitch', 'VIDEO_40_LLD_Roll', 'VIDEO_40_LLD_Opt_mean',\n","        'VIDEO_40_LLD_Opt_std', 'VIDEO_40_LLD_AU1_delta', 'VIDEO_40_LLD_AU2_delta', 'VIDEO_40_LLD_AU4_delta', 'VIDEO_40_LLD_AU5_delta', 'VIDEO_40_LLD_AU6_delta', 'VIDEO_40_LLD_AU7_delta', 'VIDEO_40_LLD_AU9_delta',\n","        'VIDEO_40_LLD_AU11_delta', 'VIDEO_40_LLD_AU12_delta', 'VIDEO_40_LLD_AU15_delta', 'VIDEO_40_LLD_AU17_delta', 'VIDEO_40_LLD_AU20_delta', 'VIDEO_40_LLD_AU23_delta', 'VIDEO_40_LLD_AU24_delta', 'VIDEO_40_LLD_AU25_delta',\n","        'VIDEO_40_LLD_Yaw_delta', 'VIDEO_40_LLD_Pitch_delta', 'VIDEO_40_LLD_Roll_delta', 'VIDEO_40_LLD_Opt_mean_delta', 'VIDEO_40_LLD_Opt_std_delta', 'Face_detection_probability', 'ECG_54_LLD_ECG_HR', 'ECG_54_LLD_ECG_HRV',\n","        'ECG_54_LLD_ECG_zcr', 'ECG_54_LLD_ECG_FFT_1', 'ECG_54_LLD_ECG_FFT_2', 'ECG_54_LLD_ECG_FFT_3', 'ECG_54_LLD_ECG_FFT_4', 'ECG_54_LLD_ECG_FFT_5', 'ECG_54_LLD_ECG_FFT_6', 'ECG_54_LLD_ECG_FFT_7', 'ECG_54_LLD_ECG_FFT_8',\n","        'ECG_54_LLD_ECG_FFT_9', 'ECG_54_LLD_ECG_FFT_10', 'ECG_54_LLD_ECG_FFT_11', 'ECG_54_LLD_ECG_FFT_12', 'ECG_54_LLD_ECG_FFT_entropy', 'ECG_54_LLD_ECG_FFT_mean_frequency', 'ECG_54_LLD_ECG_FFT_slope', 'ECG_54_LLD_ECG_mean',\n","        'ECG_54_LLD_ECG_std', 'ECG_54_LLD_ECG_kurtosis', 'ECG_54_LLD_ECG_skewness', 'ECG_54_LLD_ECG_NSImn', 'ECG_54_LLD_ECG_NLDmn', 'ECG_54_LLD_ECG_VLF', 'ECG_54_LLD_ECG_LF', 'ECG_54_LLD_ECG_HF', 'ECG_54_LLD_ECG_LFHF', 'ECG_54_LLD_ECG_zcr_delta',\n","        'ECG_54_LLD_ECG_FFT_1_delta', 'ECG_54_LLD_ECG_FFT_2_delta', 'ECG_54_LLD_ECG_FFT_3_delta', 'ECG_54_LLD_ECG_FFT_4_delta', 'ECG_54_LLD_ECG_FFT_5_delta', 'ECG_54_LLD_ECG_FFT_6_delta', 'ECG_54_LLD_ECG_FFT_7_delta', 'ECG_54_LLD_ECG_FFT_8_delta',\n","        'ECG_54_LLD_ECG_FFT_9_delta', 'ECG_54_LLD_ECG_FFT_10_delta', 'ECG_54_LLD_ECG_FFT_11_delta', 'ECG_54_LLD_ECG_FFT_12_delta', 'ECG_54_LLD_ECG_FFT_entropy_delta', 'ECG_54_LLD_ECG_FFT_mean_frequency_delta', 'ECG_54_LLD_ECG_FFT_slope_delta', 'ECG_54_LLD_ECG_mean_delta',\n","        'ECG_54_LLD_ECG_std_delta', 'ECG_54_LLD_ECG_kurtosis_delta', 'ECG_54_LLD_ECG_skewness_delta', 'ECG_54_LLD_ECG_NSImn_delta', 'ECG_54_LLD_ECG_NLDmn_delta', 'ECG_54_LLD_ECG_VLF_delta', 'ECG_54_LLD_ECG_LF_delta', 'ECG_54_LLD_ECG_HF_delta', 'ECG_54_LLD_ECG_LFHF_delta',\n","        'EDA_62_LLD_time_code', 'EDA_62_LLD_EDA_slope', 'EDA_62_LLD_EDA_std', 'EDA_62_LLD_SCR_FFT_entropy', 'EDA_62_LLD_SCR_FFT_mean_frequency', 'EDA_62_LLD_EDA_mean', 'EDA_62_LLD_EDA_meanD', 'EDA_62_LLD_EDA_meanDneg', 'EDA_62_LLD_EDA_prop', 'EDA_62_LLD_EDA_Xbound', 'EDA_62_LLD_EDA_kurtosis',\n","        'EDA_62_LLD_EDA_skewness', 'EDA_62_LLD_EDA_NSImn', 'EDA_62_LLD_EDA_NLDmn', 'EDA_62_LLD_SCL_mean', 'EDA_62_LLD_SCL_meanD', 'EDA_62_LLD_SCL_meanDneg', 'EDA_62_LLD_SCL_prop', 'EDA_62_LLD_SCL_Xbound', 'EDA_62_LLD_SCL_kurtosis', 'EDA_62_LLD_SCL_skewness', 'EDA_62_LLD_SCL_NSImn',\n","        'EDA_62_LLD_SCL_NLDmn', 'EDA_62_LLD_SCR_mean', 'EDA_62_LLD_SCR_meanD', 'EDA_62_LLD_SCR_meanDneg', 'EDA_62_LLD_SCR_prop', 'EDA_62_LLD_SCR_Xbound', 'EDA_62_LLD_SCR_kurtosis', 'EDA_62_LLD_SCR_skewness', 'EDA_62_LLD_SCR_NSImn', 'EDA_62_LLD_SCR_NLDmn', 'EDA_62_LLD_EDA_slope_delta',\n","        'EDA_62_LLD_EDA_std_delta', 'EDA_62_LLD_SCR_FFT_entropy_delta', 'EDA_62_LLD_SCR_FFT_mean_frequency_delta', 'EDA_62_LLD_EDA_mean_delta', 'EDA_62_LLD_EDA_meanD_delta', 'EDA_62_LLD_EDA_meanDneg_delta', 'EDA_62_LLD_EDA_prop_delta', 'EDA_62_LLD_EDA_Xbound_delta', 'EDA_62_LLD_EDA_kurtosis_delta',\n","        'EDA_62_LLD_EDA_skewness_delta', 'EDA_62_LLD_EDA_NSImn_delta', 'EDA_62_LLD_EDA_NLDmn_delta', 'EDA_62_LLD_SCL_mean_delta', 'EDA_62_LLD_SCL_meanD_delta', 'EDA_62_LLD_SCL_meanDneg_delta', 'EDA_62_LLD_SCL_prop_delta', 'EDA_62_LLD_SCL_Xbound_delta', 'EDA_62_LLD_SCL_kurtosis_delta', 'EDA_62_LLD_SCL_skewness_delta',\n","        'EDA_62_LLD_SCL_NSImn_delta', 'EDA_62_LLD_SCL_NLDmn_delta', 'EDA_62_LLD_SCR_mean_delta', 'EDA_62_LLD_SCR_meanD_delta', 'EDA_62_LLD_SCR_meanDneg_delta', 'EDA_62_LLD_SCR_prop_delta', 'EDA_62_LLD_SCR_Xbound_delta', 'EDA_62_LLD_SCR_kurtosis_delta', 'EDA_62_LLD_SCR_skewness_delta', 'EDA_62_LLD_SCR_NSImn_delta', 'EDA_62_LLD_SCR_NLDmn_delta'\n","\n","    ]\n","\n","    features = [col for col in combined_df.columns if col not in excluded_features + ['participant_id','median_arousal', 'median_valence', 'time_window']]\n","\n","    X = combined_df[features].values\n","    Y = combined_df[target_column].values\n","    participant_ids = combined_df['participant_id'].values\n","\n","    print(\"Starting cross-validation for arousal...\")\n","    group_kfold = GroupKFold(n_splits=10)\n","\n","    transformed_data_all = []\n","    labels_all = []\n","\n","    for fold, (train_idx, test_idx) in enumerate(group_kfold.split(X, Y, groups=participant_ids)):\n","        print(f\"\\n=====================================\")\n","        print(f\"Fold {fold+1}/{10}\")\n","        X_train = X[train_idx]\n","        Y_train = Y[train_idx]\n","        participants_train = participant_ids[train_idx]\n","        X_test, Y_test = X[test_idx], Y[test_idx]\n","        group_labels_test = participant_ids[test_idx]\n","        # Perform pairwise transformation \n","        transformed_data_path, labels_path = pairwise_transformation(X_train, Y_train, participants_train, fold)\n","\n","        # Load the transformed data and labels from the saved files\n","        X_train_transformed = load(transformed_data_path)\n","        Y_train_transformed = load(labels_path)\n","\n","        clf = RandomForestClassifier(n_estimators=15, max_depth=10, max_features='sqrt', min_samples_split=4, min_samples_leaf=2, n_jobs=-1)\n","        print(\"Starting Random Forest training...\")\n","        clf.fit(X_train_transformed, Y_train_transformed)\n","\n","        # Evaluate individual performance\n","        individual_results_df = evaluate_individual_performance(clf, X_test, Y_test, group_labels_test)\n","        evaluation_results.append(individual_results_df)\n","\n","    combined_results_df = pd.concat(evaluation_results, ignore_index=True)\n","    combined_results_csv_path = os.path.join(evaluation_results_dir, 'random_forest_evaluation_arousal.csv')\n","    combined_results_df.to_csv(combined_results_csv_path, index=False)\n","    print(\"Evaluation results saved.\")\n","\n","input_path = os.path.join(base_dir, 'RECOLA_Intervals_Data','ArousalValenceTimeSeries.csv')\n","process_data_median_arousal(input_path)"]},{"cell_type":"markdown","metadata":{"id":"Xzbrh0fvJ5PP"},"source":["- Evaluation valence"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processing data for median_valence...\n","Dataset loaded.\n","Starting cross-validation for median arousal...\n","\n","=====================================\n","Fold 1/10\n","Pairwise transformation for fold 0 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 2/10\n","Pairwise transformation for fold 1 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 3/10\n","Pairwise transformation for fold 2 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 4/10\n","Pairwise transformation for fold 3 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 5/10\n","Pairwise transformation for fold 4 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 6/10\n","Pairwise transformation for fold 5 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 7/10\n","Pairwise transformation for fold 6 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 8/10\n","Pairwise transformation for fold 7 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 9/10\n","Pairwise transformation for fold 8 completed and data saved.\n","Starting Random Forest training...\n","\n","=====================================\n","Fold 10/10\n","Pairwise transformation for fold 9 completed and data saved.\n","Starting Random Forest training...\n","Evaluation results saved.\n"]}],"source":["base_dir = 'RECOLA Ranking Algorithms'\n","valence_dir = os.path.join(base_dir, 'Random Forest/Valence')\n","evaluation_results_dir = os.path.join(base_dir, 'Evaluation/RandomForest')\n","\n","def pairwise_transformation(X, Y, participant_ids, fold_number):\n","    transformed_data_path = os.path.join(valence_dir, f'transformed_data_fold_{fold_number}.pkl')\n","    labels_path = os.path.join(valence_dir, f'labels_fold_{fold_number}.pkl')\n","\n","    # Check if files already exist\n","    if os.path.exists(transformed_data_path) and os.path.exists(labels_path):\n","        print(f\"Files for fold {fold_number} already exist. Loading from disk.\")\n","        transformed_data = load(transformed_data_path)\n","        labels = load(labels_path)\n","    else:\n","        transformed_data = []\n","        labels = []\n","        unique_participants = np.unique(participant_ids)\n","\n","        for participant in unique_participants:\n","            participant_mask = participant_ids == participant\n","            X_participant = X[participant_mask]\n","            Y_participant = Y[participant_mask]\n","\n","            for i in range(len(X_participant)):\n","                for j in range(len(X_participant)):\n","                    if j == i:\n","                        continue\n","                    xi, xj = X_participant[i], X_participant[j]\n","                    yi, yj = Y_participant[i], Y_participant[j]\n","                    if yi > yj:\n","                        transformed_data.append(xi - xj)\n","                        labels.append(1)\n","                    elif yi < yj:\n","                        transformed_data.append(xj - xi)\n","                        labels.append(0)\n","\n","        # Save the transformed data \n","        dump(transformed_data, transformed_data_path)\n","        dump(labels, labels_path)\n","        print(f\"Pairwise transformation for fold {fold_number} completed and data saved.\")\n","\n","    return transformed_data_path, labels_path\n","\n","def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    ccc = numerator / denominator\n","    return ccc\n","\n","def pearson_correlation_coefficient(y_true, y_pred):\n","    pcc, _ = pearsonr(y_true, y_pred)\n","    return pcc\n","\n","def kendalls_tau_coefficient(y_true, y_pred):\n","\n","    tau, _ = kendalltau(y_true, y_pred)\n","    return tau\n","\n","def evaluate_individual_performance(clf, X_test, Y_test, group_labels):\n","    evaluation_results = []\n","\n","    for participant_id in np.unique(group_labels):\n","\n","        idx = group_labels == participant_id\n","        participant_features = X_test[idx]\n","        participant_labels = Y_test[idx]\n","\n","        # Compute mean feature values for participant\n","        mean_features = np.mean(participant_features, axis=0)\n","\n","        # Pairwise transformation\n","        transformed_features = participant_features - mean_features\n","\n","        # Pass the transformed data through the trained RF model to predict probabilities\n","        predicted_probabilities = clf.predict_proba(transformed_features)[:, 1]\n","\n","        # Calculate measures with the raw arousal values\n","        pcc_value = pearsonr(participant_labels, predicted_probabilities)[0]\n","        ccc_value = concordance_correlation_coefficient(participant_labels, predicted_probabilities)\n","        kendall_tau_value = kendalltau(participant_labels, predicted_probabilities)[0]\n","\n","        evaluation_results.append({\n","            'Participant ID': participant_id,\n","            'PCC': pcc_value,\n","            'CCC': ccc_value,\n","            'KendallTau': kendall_tau_value\n","        })\n","\n","    return pd.DataFrame(evaluation_results)\n","\n","evaluation_results = []\n","\n","def process_data_median_valence(file_path):\n","    target_column = 'median_valence'\n","    print(f\"\\nProcessing data for {target_column}...\")\n","\n","    combined_df = pd.read_csv(file_path)\n","    print(\"Dataset loaded.\")\n","\n","    \n","    excluded_features = [\n","        'VIDEO_40_LLD_AU1', 'VIDEO_40_LLD_AU2', 'VIDEO_40_LLD_AU4', 'VIDEO_40_LLD_AU5', 'VIDEO_40_LLD_AU6', 'VIDEO_40_LLD_AU7', 'VIDEO_40_LLD_AU9', 'VIDEO_40_LLD_AU11', 'VIDEO_40_LLD_AU12', 'VIDEO_40_LLD_AU15',\n","        'VIDEO_40_LLD_AU17', 'VIDEO_40_LLD_AU20', 'VIDEO_40_LLD_AU23', 'VIDEO_40_LLD_AU24', 'VIDEO_40_LLD_AU25', 'VIDEO_40_LLD_Yaw', 'VIDEO_40_LLD_Pitch', 'VIDEO_40_LLD_Roll', 'VIDEO_40_LLD_Opt_mean',\n","        'VIDEO_40_LLD_Opt_std', 'VIDEO_40_LLD_AU1_delta', 'VIDEO_40_LLD_AU2_delta', 'VIDEO_40_LLD_AU4_delta', 'VIDEO_40_LLD_AU5_delta', 'VIDEO_40_LLD_AU6_delta', 'VIDEO_40_LLD_AU7_delta', 'VIDEO_40_LLD_AU9_delta',\n","        'VIDEO_40_LLD_AU11_delta', 'VIDEO_40_LLD_AU12_delta', 'VIDEO_40_LLD_AU15_delta', 'VIDEO_40_LLD_AU17_delta', 'VIDEO_40_LLD_AU20_delta', 'VIDEO_40_LLD_AU23_delta', 'VIDEO_40_LLD_AU24_delta', 'VIDEO_40_LLD_AU25_delta',\n","        'VIDEO_40_LLD_Yaw_delta', 'VIDEO_40_LLD_Pitch_delta', 'VIDEO_40_LLD_Roll_delta', 'VIDEO_40_LLD_Opt_mean_delta', 'VIDEO_40_LLD_Opt_std_delta', 'Face_detection_probability', 'ECG_54_LLD_ECG_HR', 'ECG_54_LLD_ECG_HRV',\n","        'ECG_54_LLD_ECG_zcr', 'ECG_54_LLD_ECG_FFT_1', 'ECG_54_LLD_ECG_FFT_2', 'ECG_54_LLD_ECG_FFT_3', 'ECG_54_LLD_ECG_FFT_4', 'ECG_54_LLD_ECG_FFT_5', 'ECG_54_LLD_ECG_FFT_6', 'ECG_54_LLD_ECG_FFT_7', 'ECG_54_LLD_ECG_FFT_8',\n","        'ECG_54_LLD_ECG_FFT_9', 'ECG_54_LLD_ECG_FFT_10', 'ECG_54_LLD_ECG_FFT_11', 'ECG_54_LLD_ECG_FFT_12', 'ECG_54_LLD_ECG_FFT_entropy', 'ECG_54_LLD_ECG_FFT_mean_frequency', 'ECG_54_LLD_ECG_FFT_slope', 'ECG_54_LLD_ECG_mean',\n","        'ECG_54_LLD_ECG_std', 'ECG_54_LLD_ECG_kurtosis', 'ECG_54_LLD_ECG_skewness', 'ECG_54_LLD_ECG_NSImn', 'ECG_54_LLD_ECG_NLDmn', 'ECG_54_LLD_ECG_VLF', 'ECG_54_LLD_ECG_LF', 'ECG_54_LLD_ECG_HF', 'ECG_54_LLD_ECG_LFHF', 'ECG_54_LLD_ECG_zcr_delta',\n","        'ECG_54_LLD_ECG_FFT_1_delta', 'ECG_54_LLD_ECG_FFT_2_delta', 'ECG_54_LLD_ECG_FFT_3_delta', 'ECG_54_LLD_ECG_FFT_4_delta', 'ECG_54_LLD_ECG_FFT_5_delta', 'ECG_54_LLD_ECG_FFT_6_delta', 'ECG_54_LLD_ECG_FFT_7_delta', 'ECG_54_LLD_ECG_FFT_8_delta',\n","        'ECG_54_LLD_ECG_FFT_9_delta', 'ECG_54_LLD_ECG_FFT_10_delta', 'ECG_54_LLD_ECG_FFT_11_delta', 'ECG_54_LLD_ECG_FFT_12_delta', 'ECG_54_LLD_ECG_FFT_entropy_delta', 'ECG_54_LLD_ECG_FFT_mean_frequency_delta', 'ECG_54_LLD_ECG_FFT_slope_delta', 'ECG_54_LLD_ECG_mean_delta',\n","        'ECG_54_LLD_ECG_std_delta', 'ECG_54_LLD_ECG_kurtosis_delta', 'ECG_54_LLD_ECG_skewness_delta', 'ECG_54_LLD_ECG_NSImn_delta', 'ECG_54_LLD_ECG_NLDmn_delta', 'ECG_54_LLD_ECG_VLF_delta', 'ECG_54_LLD_ECG_LF_delta', 'ECG_54_LLD_ECG_HF_delta', 'ECG_54_LLD_ECG_LFHF_delta',\n","        'EDA_62_LLD_time_code', 'EDA_62_LLD_EDA_slope', 'EDA_62_LLD_EDA_std', 'EDA_62_LLD_SCR_FFT_entropy', 'EDA_62_LLD_SCR_FFT_mean_frequency', 'EDA_62_LLD_EDA_mean', 'EDA_62_LLD_EDA_meanD', 'EDA_62_LLD_EDA_meanDneg', 'EDA_62_LLD_EDA_prop', 'EDA_62_LLD_EDA_Xbound', 'EDA_62_LLD_EDA_kurtosis',\n","        'EDA_62_LLD_EDA_skewness', 'EDA_62_LLD_EDA_NSImn', 'EDA_62_LLD_EDA_NLDmn', 'EDA_62_LLD_SCL_mean', 'EDA_62_LLD_SCL_meanD', 'EDA_62_LLD_SCL_meanDneg', 'EDA_62_LLD_SCL_prop', 'EDA_62_LLD_SCL_Xbound', 'EDA_62_LLD_SCL_kurtosis', 'EDA_62_LLD_SCL_skewness', 'EDA_62_LLD_SCL_NSImn',\n","        'EDA_62_LLD_SCL_NLDmn', 'EDA_62_LLD_SCR_mean', 'EDA_62_LLD_SCR_meanD', 'EDA_62_LLD_SCR_meanDneg', 'EDA_62_LLD_SCR_prop', 'EDA_62_LLD_SCR_Xbound', 'EDA_62_LLD_SCR_kurtosis', 'EDA_62_LLD_SCR_skewness', 'EDA_62_LLD_SCR_NSImn', 'EDA_62_LLD_SCR_NLDmn', 'EDA_62_LLD_EDA_slope_delta',\n","        'EDA_62_LLD_EDA_std_delta', 'EDA_62_LLD_SCR_FFT_entropy_delta', 'EDA_62_LLD_SCR_FFT_mean_frequency_delta', 'EDA_62_LLD_EDA_mean_delta', 'EDA_62_LLD_EDA_meanD_delta', 'EDA_62_LLD_EDA_meanDneg_delta', 'EDA_62_LLD_EDA_prop_delta', 'EDA_62_LLD_EDA_Xbound_delta', 'EDA_62_LLD_EDA_kurtosis_delta',\n","        'EDA_62_LLD_EDA_skewness_delta', 'EDA_62_LLD_EDA_NSImn_delta', 'EDA_62_LLD_EDA_NLDmn_delta', 'EDA_62_LLD_SCL_mean_delta', 'EDA_62_LLD_SCL_meanD_delta', 'EDA_62_LLD_SCL_meanDneg_delta', 'EDA_62_LLD_SCL_prop_delta', 'EDA_62_LLD_SCL_Xbound_delta', 'EDA_62_LLD_SCL_kurtosis_delta', 'EDA_62_LLD_SCL_skewness_delta',\n","        'EDA_62_LLD_SCL_NSImn_delta', 'EDA_62_LLD_SCL_NLDmn_delta', 'EDA_62_LLD_SCR_mean_delta', 'EDA_62_LLD_SCR_meanD_delta', 'EDA_62_LLD_SCR_meanDneg_delta', 'EDA_62_LLD_SCR_prop_delta', 'EDA_62_LLD_SCR_Xbound_delta', 'EDA_62_LLD_SCR_kurtosis_delta', 'EDA_62_LLD_SCR_skewness_delta', 'EDA_62_LLD_SCR_NSImn_delta', 'EDA_62_LLD_SCR_NLDmn_delta'\n","\n","    ]\n","\n","    features = [col for col in combined_df.columns if col not in excluded_features + ['participant_id','median_arousal', 'median_valence', 'time_window', target_column]]\n","\n","    X = combined_df[features].values\n","    Y = combined_df[target_column].values\n","    participant_ids = combined_df['participant_id'].values\n","\n","    print(\"Starting cross-validation for median arousal...\")\n","    group_kfold = GroupKFold(n_splits=10)\n","\n","    transformed_data_all = []\n","    labels_all = []\n","\n","    for fold, (train_idx, test_idx) in enumerate(group_kfold.split(X, Y, groups=participant_ids)):\n","        print(f\"\\n=====================================\")\n","        print(f\"Fold {fold+1}/{10}\")\n","        X_train = X[train_idx]\n","        Y_train = Y[train_idx]\n","        participants_train = participant_ids[train_idx]\n","        X_test, Y_test = X[test_idx], Y[test_idx]\n","        group_labels_test = participant_ids[test_idx]\n","        # Perform pairwise transformation\n","        transformed_data_path, labels_path = pairwise_transformation(X_train, Y_train, participants_train, fold)\n","\n","        # Load the transformed data \n","        X_train_transformed = load(transformed_data_path)\n","        Y_train_transformed = load(labels_path)\n","\n","        clf = RandomForestClassifier(n_estimators=15, max_depth=10, max_features='sqrt', min_samples_split=4, min_samples_leaf=2, n_jobs=-1)\n","        print(\"Starting Random Forest training...\")\n","        clf.fit(X_train_transformed, Y_train_transformed)\n","\n","        # Evaluate individual performance\n","        individual_results_df = evaluate_individual_performance(clf, X_test, Y_test, group_labels_test)\n","        evaluation_results.append(individual_results_df)\n","\n","    combined_results_df = pd.concat(evaluation_results, ignore_index=True)\n","    combined_results_csv_path = os.path.join(evaluation_results_dir, 'random_forest_evaluation_valence.csv')\n","    combined_results_df.to_csv(combined_results_csv_path, index=False)\n","    print(\"Evaluation results saved.\")\n","\n","input_path = os.path.join('RECOLA Ranking Algorithms', 'RECOLA_Intervals_Data','ArousalValenceTimeSeries.csv')\n","process_data_median_valence(input_path)"]},{"cell_type":"markdown","metadata":{"id":"1KWNsbKNJ_Z2"},"source":["# Ordinal Logistic Regression"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"]},{"name":"stdout","output_type":"stream","text":["Results for arousal saved in RECOLA Ranking Algorithms/Evaluation/Ordinal Logistic Regression\\arousal_evaluation_results.csv.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n","c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"]},{"name":"stdout","output_type":"stream","text":["Results for valence saved in RECOLA Ranking Algorithms/Evaluation/Ordinal Logistic Regression\\valence_evaluation_results.csv.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\marco\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"]}],"source":["def label_quartiles(df, feature, label_col):\n","    for participant in df['participant_id'].unique():\n","        \n","        participant_data = df[df['participant_id'] == participant]\n","        \n","        quartile_10 = np.percentile(participant_data[feature], 10)  \n","        quartile_25 = np.percentile(participant_data[feature], 25)\n","        quartile_50 = np.percentile(participant_data[feature], 50)\n","        quartile_75 = np.percentile(participant_data[feature], 75)\n","        \n","        percentiles = [\n","            np.percentile(participant_data[feature], 86),\n","            np.percentile(participant_data[feature], 72),\n","            np.percentile(participant_data[feature], 58),\n","            np.percentile(participant_data[feature], 43),\n","            np.percentile(participant_data[feature], 28),\n","            np.percentile(participant_data[feature], 14),\n","        ]\n","        \n","        # Combine all thresholds \n","        bins = [-np.inf] + sorted([quartile_10, quartile_25, quartile_50, quartile_75] + percentiles) + [np.inf]\n","        \n","        labels = np.digitize(participant_data[feature], bins) - 1\n","        df.loc[participant_data.index, label_col] = labels\n","\n","def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    return numerator / denominator\n","\n","def pearson_correlation_coefficient(y_true, y_pred):\n","    pcc, _ = pearsonr(y_true, y_pred)\n","    return pcc\n","\n","def kendalls_tau_coefficient(y_true, y_pred):\n","\n","    tau, _ = kendalltau(y_true, y_pred)\n","    return tau\n","\n","def evaluate_individual_performance(X_test, Y_test, group_labels, linpred_test):\n","    evaluation_results = []\n","    for participant_id in np.unique(group_labels):\n","        idx = group_labels == participant_id\n","        participant_labels = Y_test[idx]\n","        participant_predictions = linpred_test[idx]\n","        pcc_value = pearsonr(participant_labels, participant_predictions)[0]\n","        ccc_value = concordance_correlation_coefficient(participant_labels, participant_predictions)\n","        kendall_tau_value = kendalltau(participant_labels, participant_predictions)[0]\n","        evaluation_results.append({\n","            'Participant ID': participant_id,\n","            'PCC': pcc_value,\n","            'CCC': ccc_value,\n","            'KendallTau': kendall_tau_value\n","        })\n","    return pd.DataFrame(evaluation_results)\n","\n","def process_target(df, features, label_col, participant_ids, group_kfold, target_name):\n","    evaluation_results = []\n","    X = df[features].values\n","    Y = df[label_col].values\n","\n","    for train_index, test_index in group_kfold.split(X, Y, groups=participant_ids):\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test = Y[train_index], Y[test_index]\n","        group_labels_test = df['participant_id'].iloc[test_index].values\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter('ignore', HessianInversionWarning)\n","            model = OrderedModel(Y_train, X_train, distr='logit')\n","            result = model.fit(method='bfgs', disp=False)\n","\n","            linpred_test = result.predict(X_test, which='linpred')\n","            individual_results_df = evaluate_individual_performance(X_test, Y_test, group_labels_test, linpred_test)\n","            evaluation_results.append(individual_results_df)\n","\n","    final_results_df = pd.concat(evaluation_results, ignore_index=True)\n","    output_folder = 'RECOLA Ranking Algorithms/Evaluation/Ordinal Logistic Regression'\n","    output_filename = os.path.join(output_folder, f\"{target_name}_evaluation_results.csv\")\n","    final_results_df.to_csv(output_filename, index=False)\n","    print(f\"Results for {target_name} saved in {output_filename}.\")\n","\n","def process_data(filepath):\n","    df = pd.read_csv(filepath)\n","    df['arousal_quartile'] = -1\n","    df['valence_quartile'] = -1\n","\n","    label_quartiles(df, 'median_arousal', 'arousal_quartile')\n","    label_quartiles(df, 'median_valence', 'valence_quartile')\n","\n","    group_kfold = GroupKFold(n_splits=10)\n","    participant_ids = df['participant_id'].values\n","    features = [col for col in df.columns if col not in ['participant_id', 'median_arousal', 'median_valence', 'time_window', 'arousal_quartile', 'valence_quartile']]\n","\n","    process_target(df, features, 'arousal_quartile', participant_ids, group_kfold, 'arousal')\n","    process_target(df, features, 'valence_quartile', participant_ids, group_kfold, 'valence')\n","\n","filepath = os.path.join(base_dir,'RECOLA Ranking Algorithms', 'RECOLA_Intervals_Data', 'ArousalValenceTimeSeries_Quartiles.csv')\n","if os.path.exists(filepath):\n","    process_data(filepath)\n","else:\n","    print(f\"File {filepath} not found. Please ensure it exists in the specified path.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Regression"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    return numerator / denominator\n","\n","def evaluate_individual_performance( Y_test, group_labels, predictions):\n","    evaluation_results = []\n","    for participant_id in np.unique(group_labels):\n","        idx = group_labels == participant_id\n","        participant_labels = Y_test[idx]\n","        participant_predictions = predictions[idx]\n","        pcc_value = pearsonr(participant_labels, participant_predictions)[0]\n","        ccc_value = concordance_correlation_coefficient(participant_labels, participant_predictions)\n","        kendall_tau_value = kendalltau(participant_labels, participant_predictions)[0]\n","        evaluation_results.append({\n","            'Participant ID': participant_id,\n","            'PCC': pcc_value,\n","            'CCC': ccc_value,\n","            'KendallTau': kendall_tau_value\n","        })\n","    return evaluation_results\n","\n","def process_target(df, features, continuous_target, participant_ids, group_kfold, model_type):\n","    all_results = []\n","    X = df[features].values\n","    Y = df[continuous_target].values\n","\n","    for train_index, test_index in group_kfold.split(X, Y, groups=participant_ids):\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test = Y[train_index], Y[test_index]\n","        group_labels_test = df['participant_id'].iloc[test_index].values\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter('ignore', HessianInversionWarning)\n","\n","            if model_type == 'linear':\n","                reg = LinearRegression().fit(X_train, Y_train)\n","                y_linear_model_pred = reg.predict(X_test)\n","                all_results.extend(evaluate_individual_performance(Y_test, group_labels_test, y_linear_model_pred))\n","            elif model_type == 'random_forest':\n","                reg = RandomForestRegressor(random_state=0).fit(X_train, Y_train)\n","                y_random_forest_pred = reg.predict(X_test)\n","                all_results.extend(evaluate_individual_performance(Y_test, group_labels_test, y_random_forest_pred))\n","            elif model_type == 'mlp':\n","                reg = MLPRegressor(hidden_layer_sizes=(64, 32), random_state=1, max_iter=1000).fit(X_train, Y_train)\n","                y_mlp_pred = reg.predict(X_test)\n","                all_results.extend(evaluate_individual_performance(Y_test, group_labels_test, y_mlp_pred))\n","\n","    return all_results\n","\n","\n","def process_data(filepath):\n","    df = pd.read_csv(filepath)\n","    group_kfold = GroupKFold(n_splits=10)\n","    participant_ids = df['participant_id'].values\n","    features = [col for col in df.columns if col not in ['participant_id','median_arousal','median_valence','time_window','time in seconds','FM1 _x', 'FM2 _x', 'FM3 _x', 'FF1 _x', 'FF2 _x', 'FF3_x','FM1 _y', 'FM2 _y', 'FM3 _y', 'FF1 _y', 'FF2 _y', 'FF3_y']]\n","\n","    for target_col, target_name in [('median_arousal', 'arousal'), ('median_valence', 'valence')]:\n","        for model in ['linear', 'random_forest', 'mlp']:\n","            results = process_target(df, features, target_col, participant_ids, group_kfold, model)\n","            pd.DataFrame(results).to_csv(f'RECOLA Ranking Algorithms\\Evaluation\\Regression\\{model}_regression_evaluation_{target_name}.csv', index=False)\n","\n","\n","filepath = os.path.join(base_dir, 'RECOLA Ranking Algorithms', 'RECOLA_Intervals_Data', 'ArousalValenceTimeSeries.csv')\n","if os.path.exists(filepath):\n","    process_data(filepath)\n","else:\n","    print(f\"File {filepath} not found. Please ensure it exists in the specified path.\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPQpvcip7ecQgU5Nt5tFfjm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
