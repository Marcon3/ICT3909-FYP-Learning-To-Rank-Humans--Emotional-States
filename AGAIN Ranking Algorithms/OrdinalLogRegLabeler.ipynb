{"cells":[{"cell_type":"markdown","metadata":{"id":"BmLABHlHBoOW"},"source":["# Ordinal Logistic Regression (Thresholds)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2089,"status":"ok","timestamp":1710258417119,"user":{"displayName":"Marcon Spiteri","userId":"03188949906581882183"},"user_tz":-60},"id":"nZbvg6L7CkkP"},"outputs":[],"source":["# Importing Libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import warnings\n","from sklearn.metrics import accuracy_score\n","from scipy.stats import pearsonr, kendalltau\n","from sklearn.model_selection import GroupKFold\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from statsmodels.miscmodels.ordinal_model import OrderedModel\n","from statsmodels.tools.sm_exceptions import HessianInversionWarning"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["project_directory = r'C:\\Users\\marco\\OneDrive\\Desktop\\Final Year Project'\n","os.chdir(project_directory)\n","base_dir = os.getcwd() "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The csv file with percentile labels has been created successfully.\n","Combined individual performance evaluation results saved.\n","\n","Average Training and Testing Accuracies by Game:\n","Heist!: Training Accuracy = 4.13%, Testing Accuracy = 4.01%\n","Shootout: Training Accuracy = 5.00%, Testing Accuracy = 4.80%\n","TopDown: Training Accuracy = 4.13%, Testing Accuracy = 3.99%\n","\n","Overall Average Training Accuracy: 4.42%\n","Overall Average Testing Accuracy: 4.27%\n"]}],"source":["def label_percentile(y_values):\n","    \n","    all_thresholds = []\n","\n","    \n","    all_thresholds.extend([\n","        np.percentile(y_values, 80),\n","        np.percentile(y_values, 60),\n","        np.percentile(y_values, 40),\n","        np.percentile(y_values, 20),\n","    ])\n","\n","    \n","    all_thresholds.extend([\n","       np.percentile(y_values, 86),\n","       np.percentile(y_values, 72),\n","       np.percentile(y_values, 58),\n","       np.percentile(y_values, 43),\n","       np.percentile(y_values, 28),\n","       np.percentile(y_values, 14),\n","    ])\n","\n","    \n","    all_thresholds = sorted(set(all_thresholds))\n","    labels = np.digitize(y_values, all_thresholds)\n","    return labels \n","\n","# File paths\n","input_file = os.path.join('AGAIN Ranking Algorithms', 'intervals_data.csv')\n","output_file = os.path.join('AGAIN Ranking Algorithms', 'Data_Percentiles', 'ordinal_logistic_regression_percentiles.csv')\n","\n","df = pd.read_csv(input_file)\n","\n","def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    ccc = numerator / denominator\n","    return ccc\n","\n","def pearson_correlation_coefficient(y_true, y_pred):\n","    pcc, _ = pearsonr(y_true, y_pred)\n","    return pcc\n","\n","def kendalls_tau_coefficient(y_true, y_pred):\n","    tau, _ = kendalltau(y_true, y_pred)\n","    return tau\n","\n","def evaluate_individual_performance(X_test, Y_test, group_labels, linpred_test, game_name):\n","    evaluation_results = []\n","    for participant_id in np.unique(group_labels):\n","        idx = group_labels == participant_id\n","        participant_labels = Y_test[idx]\n","        participant_predictions = linpred_test[idx]\n","        pcc_value = pearsonr(participant_labels, participant_predictions)[0]\n","        ccc_value = concordance_correlation_coefficient(participant_labels, participant_predictions)\n","        kendall_tau_value = kendalltau(participant_labels, participant_predictions)[0]\n","\n","        evaluation_results.append({\n","            'Game Name': game_name,\n","            'Participant ID': participant_id,\n","            'PCC': pcc_value,\n","            'CCC': ccc_value,\n","            'KendallTau': kendall_tau_value\n","        })\n","    return pd.DataFrame(evaluation_results)\n","\n","# Label arousal values using percentile based categories and save in a new column\n","df['arousal_label']= label_percentile(df['[output]arousal'].values)\n","\n","# Save the dataframe with new labels into a new csv file\n","df.to_csv(output_file, index=False)\n","print(\"The csv file with percentile labels has been created successfully.\")\n","\n","# Initialize lists to store train and test accuracies\n","evaluation_results = []\n","train_accuracies = []\n","test_accuracies = []\n","\n","# Implement GroupKFold\n","group_kfold = GroupKFold(n_splits=10)\n","games = df['[control]game'].unique()\n","\n","# Loop through each game\n","for game in games:\n","    game_df = df[df['[control]game'] == game]\n","    feature_cols = [col for col in df.columns if '[general]' in col]\n","    X = game_df[feature_cols]\n","    Y = game_df['arousal_label']\n","    groups = game_df['[control]player_id']\n","\n","    train_accuracies_game = []\n","    test_accuracies_game = []\n","\n","    # Split the data into training and testing sets based on groups\n","    for train_index, test_index in group_kfold.split(X, Y, groups):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n","        group_labels_test = game_df['[control]player_id'].iloc[test_index].values\n","\n","        # Remove the warnings\n","        with warnings.catch_warnings():\n","            warnings.simplefilter('ignore', category=HessianInversionWarning)\n","\n","            # Ordinal Logistic Regression using OrderedModel from stastmodels\n","            model = OrderedModel(Y_train, X_train, distr='logit')\n","            result = model.fit(method='bfgs', disp=False)\n","            \n","            # Prediction\n","            prob_train = result.predict(X_train)\n","            prob_test = result.predict(X_test)\n","            linpred_test = result.predict(X_test, which='linpred')\n","\n","            Y_pred_train = np.argmax(prob_train.values, axis=1) + 1\n","            Y_pred_test = np.argmax(prob_test.values, axis=1) + 1\n","\n","            train_accuracies_game.append(accuracy_score(Y_train, Y_pred_train) * 100)\n","            test_accuracies_game.append(accuracy_score(Y_test, Y_pred_test) * 100)\n","\n","            individual_results_df = evaluate_individual_performance(X_test, Y_test, group_labels_test, linpred_test, game)\n","            evaluation_results.append(individual_results_df)\n","    \n","    # Store average accuracies for this game\n","    train_accuracies.append(np.mean(train_accuracies_game))\n","    test_accuracies.append(np.mean(test_accuracies_game))\n","\n","output_folder = 'AGAIN Ranking Algorithms/Evaluation/Ordinal Logistic Regression'\n","output_file = 'OLR_evaluation_result.csv'\n","combined_results_df = pd.concat(evaluation_results, ignore_index=True)\n","combined_results_df.to_csv(os.path.join(output_folder, output_file), index=False)\n","\n","print(\"Combined individual performance evaluation results saved.\")\n","\n","print(\"\\nAverage Training and Testing Accuracies by Game:\")\n","for i, game in enumerate(games):\n","    print(f\"{game}: Training Accuracy = {train_accuracies[i]:.2f}%, Testing Accuracy = {test_accuracies[i]:.2f}%\")\n","\n","# Calculate and print the overall average accuracies\n","overall_train_accuracy = np.mean(train_accuracies)\n","overall_test_accuracy = np.mean(test_accuracies)\n","print(f\"\\nOverall Average Training Accuracy: {overall_train_accuracy:.2f}%\")\n","print(f\"Overall Average Testing Accuracy: {overall_test_accuracy:.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["## Regression"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["input_file = os.path.join('AGAIN Ranking Algorithms', 'intervals_data.csv')\n","df = pd.read_csv(input_file)\n","\n","group_kfold = GroupKFold(n_splits=10)\n","games = df['[control]game'].unique()\n","\n","linear_results = []\n","random_forest_results = []\n","mlp_results = []\n","\n","def concordance_correlation_coefficient(y_true, y_pred):\n","    cor = np.corrcoef(y_true, y_pred)[0][1]\n","    mean_true, mean_pred = np.mean(y_true), np.mean(y_pred)\n","    var_true, var_pred = np.var(y_true), np.var(y_pred)\n","    sd_true, sd_pred = np.std(y_true), np.std(y_pred)\n","    numerator = 2 * cor * sd_true * sd_pred\n","    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n","    ccc = numerator / denominator\n","    return ccc\n","\n","def pearson_correlation_coefficient(y_true, y_pred):\n","    pcc, _ = pearsonr(y_true, y_pred)\n","    return pcc\n","\n","def kendalls_tau_coefficient(y_true, y_pred):\n","    tau, _ = kendalltau(y_true, y_pred)\n","    return tau\n","\n","def evaluation_function(y_test, group_labels, predictions, results_list, game_name):\n","    for participant_id in np.unique(group_labels):\n","        idx = group_labels == participant_id\n","        pcc = pearsonr(y_test[idx], predictions[idx])[0]\n","        ccc = concordance_correlation_coefficient(y_test[idx], predictions[idx])\n","        tau = kendalltau(y_test[idx], predictions[idx])[0]\n","        results_list.append({\n","            'Game Name': game_name,\n","            'Participant ID': participant_id,\n","            'PCC': pcc,\n","            'CCC': ccc,\n","            'KendallTau': tau\n","        })\n","\n","def calculate_averages(results_list):\n","    game_results = pd.DataFrame(results_list)\n","    numeric_results = game_results.select_dtypes(include=[np.number])\n","    game_average = numeric_results.mean()\n","    results_list.append({\n","        'Participant ID': 'Average',\n","        'PCC': game_average['PCC'],\n","        'CCC': game_average['CCC'],\n","        'KendallTau': game_average['KendallTau']\n","    })\n","\n","for game in games:\n","    game_df = df[df['[control]game'] == game]\n","    exclude_columns = ['[general]time_passed'] \n","    feature_cols = [col for col in df.columns if '[general]' in col and col not in exclude_columns]\n","    X = game_df[feature_cols]\n","    y_continuous = game_df['[output]arousal']\n","    groups = game_df['[control]player_id']\n","\n","    for train_index, test_index in group_kfold.split(X, y_continuous, groups):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y_continuous.iloc[train_index], y_continuous.iloc[test_index]\n","        group_labels_test = groups.iloc[test_index].values\n","\n","        reg_lin = LinearRegression().fit(X_train, y_train)\n","        y_lin_pred = reg_lin.predict(X_test)\n","        evaluation_function(y_test, group_labels_test, y_lin_pred, linear_results, game)\n","\n","        reg_rf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n","        y_rf_pred = reg_rf.predict(X_test)\n","        evaluation_function(y_test, group_labels_test, y_rf_pred, random_forest_results, game)\n","\n","        reg_mlp = MLPRegressor(hidden_layer_sizes=(64, 32), random_state=1, max_iter=1000).fit(X_train, y_train)\n","        y_mlp_pred = reg_mlp.predict(X_test)\n","        evaluation_function(y_test, group_labels_test, y_mlp_pred, mlp_results, game)\n","\n","    calculate_averages(linear_results)\n","    calculate_averages(random_forest_results)\n","    calculate_averages(mlp_results)\n","\n","pd.DataFrame(linear_results).to_csv('AGAIN Ranking Algorithms/Evaluation/Regression/linear_regression_evaluation_results.csv', index=False)\n","pd.DataFrame(random_forest_results).to_csv('AGAIN Ranking Algorithms/Evaluation/Regression/random_forest_evaluation_results.csv', index=False)\n","pd.DataFrame(mlp_results).to_csv('AGAIN Ranking Algorithms/Evaluation/Regression/mlp_evaluation_results.csv', index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO31lo2VoMioi5NeVan9sg+","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
